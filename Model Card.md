Model Card: Mulliken Charge Prediction Models

1. Model overview

We develop a set of supervised regression models to predict the Mulliken charge of the central Mg2+ ion from molecular descriptors of electrolyte solvents. All models are implemented in Python using the scikit-learn library (and the XGBoost package where applicable). The primary models considered in this work are:

Random forest (RF) regressor

Kernel ridge regression (KRR)

k-nearest neighbors (KNN) regressor

Extreme gradient boosting (XGBoost) regressor

The main results in the Supporting Information focus on the RF model, with KRR, KNN, and XGBoost included as comparative baselines.

2. Intended use and scope

Primary purpose:
Data-driven prediction of the Mulliken charge of Mg2+ in electrolyte solvents, and ranking/analysis of candidate solvents based on their local electronic environment.

Intended users:
Researchers working on electrolyte design, solvation structure analysis, and Mg battery chemistry.

Intended use cases:

Virtual screening of candidate solvents within a similar chemical space to the training data.

Interpreting the relative importance of different molecular descriptors for Mg2+ charge distribution.
The models are intended as a guidance and screening tool, not as a replacement for high-level quantum-chemical calculations or experimental validation.

3. Data

Data source:
All data points were generated by our own quantum-chemical (quantum-chemical) calculations using a consistent computational protocol. The underlying structures correspond to commonly used electrolyte solvents.

Solvent coverage and bias considerations:
The solvents in our dataset are all commonly used electrolyte solvents reported in the literature, and we did not deliberately focus on any specific solvent class. The selected solvents span a wide range of dielectric constants, from 2.273 to 178.9, covering low-, medium-, and high-polarity solvents. Therefore, no pronounced bias toward any particular polarity is expected. In Figure S1, we show that the data are selected randomly and broadly, with no apparent bias.

Features and target:

Input features (X): 40 molecular descriptors for each solvent, derived from quantum-chemical calculations and related structural/electronic properties.

Target (y): Mulliken charge of the central Mg2+ ion.

Data splitting:
The dataset (Dataset.xlsx) is loaded into a pandas DataFrame. The data are randomly split into training and test sets using train_test_split, with 75% of the data used for training and 25% held out for testing (random_state = 0). The split is performed at the solvent (molecule) level, so that a given solvent never appears in both the training and test sets, thereby mimicking the anticipated real-world use case of predicting properties for unseen candidate solvents and avoiding data leakage.
In addition, 5-fold cross-validation is carried out using KFold (n_splits = 5) to further assess the variability and robustness of the model performance.

4. Training and preprocessing

Software environment:

Python

scikit-learn (for RF, KRR, KNN)

XGBoost (for gradient-boosted decision trees)

pandas, numpy, matplotlib, seaborn

shap (for SHAP value analysis)

Preprocessing:
Prior to model training, all input features are standardized to zero mean and unit variance using the StandardScaler class in scikit-learn. The scaler is fitted on the training data and then applied to the test data, ensuring that no information from the test set leaks into the training process.

Training procedure:

Models are trained on the standardized training set.

5-fold cross-validation is used to estimate generalization performance and variability.

Final performance metrics are reported on the held-out test set (25% of the data).

5. Evaluation

Metrics:
Model performance is evaluated using the following regression metrics on the held-out test set:

Mean absolute error (MAE), Mean squared error (MSE), Root mean square error (RMSE)

Baselines and model comparison:
Baseline comparisons among KRR, KNN, RF, and XGBoost models are provided, with KNN and RF serving as relatively simple baseline models. The comparative results are summarized in the Supporting Information (e.g., Fig. S2 and Table S2).

External benchmarks:
To the best of our knowledge, there is currently no established community benchmark dataset or state-of-the-art reference model for this specific Mg2+ Mulliken charge prediction task on the present dataset. Consequently, the models are evaluated only on our own quantum-chemical dataset; no external benchmark dataset is used.

6. Interpretability

To investigate model interpretability and identify key molecular descriptors:

We use the built-in feature importance scores (model.feature_importances_) of the trained random forest to rank all descriptors and visualize their relative contributions to the predictions.

We further apply SHAP (SHapley Additive exPlanations) analysis using shap.TreeExplainer(model) to compute SHAP values for each feature. SHAP summary plots are used to identify and visualize the most influential descriptors governing the Mulliken charge predictions. These analyses provide a physically interpretable link between molecular descriptors and the electronic environment of Mg2+.

7. Limitations and applicability

The models are trained on a specific chemical space of electrolyte solvents generated by our quantum-chemical protocol. Predictions for molecules that are far outside this domain (e.g., very different functional groups or extreme structural motifs) may be unreliable.

All labels are computed Mulliken charges rather than experimental observables; thus, the model is constrained by the approximations and limitations of the chosen quantum-chemical method.

No fully independent external dataset (e.g., from different calculation protocols or experiments) is used for additional validation. The reported performance is based on internal train/test splits and cross-validation within the same dataset.

The models are intended as a screening and interpretability tool. Any critical conclusions for practical electrolyte design should be supported by additional high-level calculations and/or experimental measurements.

8. Availability

The complete scripts (including data loading, preprocessing, model training, cross-validation, metric evaluation, feature-importance analysis, and SHAP analysis), together with the dataset used in this study, are openly available in the following GitHub repository and will remain accessible after publication:

GitHub: https://github.com/liruimin1228-rgb/zhangmeng